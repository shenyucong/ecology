nohup: ignoring input
/home/CVL1/anaconda3/envs/shaobo/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2018-03-25 14:22:13.479838: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-25 14:22:13.920081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.911
pciBusID: 0000:82:00.0
totalMemory: 11.90GiB freeMemory: 11.73GiB
2018-03-25 14:22:13.920145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:82:00.0, compute capability: 6.1)
step 0, loss 3.2077, trainig accuracy 0.0800
step 100, loss 1.2566, trainig accuracy 0.5933
step 200, loss 0.7795, trainig accuracy 0.8000
step 300, loss 0.3303, trainig accuracy 0.8867
step 400, loss 0.3690, trainig accuracy 0.9133
step 500, loss 0.1822, trainig accuracy 0.9467
step 600, loss 0.2370, trainig accuracy 0.9333
step 700, loss 0.0335, trainig accuracy 0.9867
step 800, loss 0.1303, trainig accuracy 0.9600
step 900, loss 0.0193, trainig accuracy 0.9933
step 1000, loss 0.0250, trainig accuracy 0.9867
step 1100, loss 0.1261, trainig accuracy 0.9867
step 1200, loss 0.0018, trainig accuracy 1.0000
step 1300, loss 0.1194, trainig accuracy 0.9800
step 1400, loss 0.0739, trainig accuracy 0.9867
step 1500, loss 0.1596, trainig accuracy 0.9600
step 1600, loss 0.0455, trainig accuracy 0.9800
step 1700, loss 0.0894, trainig accuracy 0.9667
step 1800, loss 0.0030, trainig accuracy 1.0000
step 1900, loss 0.0090, trainig accuracy 0.9933
step 2000, loss 0.0013, trainig accuracy 1.0000
step 2100, loss 0.0006, trainig accuracy 1.0000
step 2200, loss 0.0669, trainig accuracy 0.9667
step 2300, loss 0.0118, trainig accuracy 1.0000
step 2400, loss 0.0061, trainig accuracy 0.9933
step 2500, loss 0.0092, trainig accuracy 1.0000
step 2600, loss 0.0467, trainig accuracy 0.9933
step 2700, loss 0.0009, trainig accuracy 1.0000
step 2800, loss 0.0543, trainig accuracy 0.9933
step 2900, loss 0.0165, trainig accuracy 1.0000
step 3000, loss 0.0703, trainig accuracy 0.9867
step 3100, loss 0.1018, trainig accuracy 0.9800
step 3200, loss 0.0180, trainig accuracy 0.9867
step 3300, loss 0.0694, trainig accuracy 0.9667
step 3400, loss 0.0035, trainig accuracy 1.0000
step 3500, loss 0.0372, trainig accuracy 0.9867
step 3600, loss 0.0833, trainig accuracy 0.9800
step 3700, loss 0.0080, trainig accuracy 1.0000
step 3800, loss 0.0730, trainig accuracy 0.9933
step 3900, loss 0.0033, trainig accuracy 1.0000
